# Journal — {{10-4-2025}} — {{DAY 4}}

## 1) What I learned (bullets, not prose)
- Data Quality
- DQ core check types
- Why DQ checks in using DBT > SQL 

## 2) New vocabulary (define in your own words)
- **Data Quality** — accuracy, completeness, reliability, relevancy, timeliness
- **Data Health Card** — snapshot of dataset quality.
  
## 3) Data Engineering mindset applied (what principles did I use?)
- **Single Source of Truth:** — ensured consistency accross outputs.

## 4) Decisions & assumptions (why, alternatives, trade-offs)
- I did more test queries on DBeaver to see how different factors interact each other in the new dataset provided. 

## 5) Open questions (things I still don’t get)
- Just how much coding is involved in data engineering?

## 6) Next actions (small, doable steps)
- [ ] - Catch up with all the technicalities
- [ ] - Practice more SQL queries
- [ ] - Keep up w DataCamp streak
- [ ] - Finish group assignment 1
- [ ] - Finish group assignment 2

## 7) Artifacts & links (code, queries, dashboards)

---

### Mini reflection (3–5 sentences)
One cannot build reliable insights on contaminated data. I’ve come to realize that no matter how complex or beautiful your data pipeline is, if the data going in is messy, everything that comes out can be compromised. It’s way easier to catch and fix problems early in the pipeline than to fix broken dashboards or corrupted models later on. It’s like fixing a leak before the whole roof collapses.

### BONUS: What is a meme that best describes what you feel or your learning today?

![lionmonkehehe](../assets/lionmonke.jpeg)
